{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Denoising Model Pipeline with ResNet and SCSE Block\n",
    "\n",
    "## 1. Architecture\n",
    "\n",
    "The architecture is a combination of a **pre-trained ResNet encoder** with an **attention-based U-Net decoder** for image denoising. This structure enables efficient feature extraction, fine-grained attention, and detail preservation.\n",
    "\n",
    "### 1.1 Overview of U-Net with Attention\n",
    "The architecture uses an **Attention U-Net** structure that leverages a pre-trained encoder, combining U-Net’s segmentation power with attention to focus on critical regions. This is particularly valuable for image denoising tasks that require retaining small, important features.\n",
    "\n",
    "### 1.2 Key Components in Detail\n",
    "\n",
    "#### Encoder (Feature Extraction - ResNet)\n",
    "\n",
    "The encoder extracts features at multiple abstraction levels, beginning with the input image and passing through ResNet layers:\n",
    "\n",
    "1. **Input Image (RGB)**: The image has 3 channels, representing RGB color channels. Let \\( X \\in \\mathbb{R}^{H \\times W \\times 3} \\) be the input image where:\n",
    "   - \\( H \\): Image height.\n",
    "   - \\( W \\): Image width.\n",
    "\n",
    "2. **Convolutional Layer**: \n",
    "   - The first layer applies a convolution to the image, producing feature maps. For an input \\( X \\), the convolutional operation is defined as:\n",
    "     $$\n",
    "     X'_{i,j} = \\sum_{m=1}^{M} \\sum_{n=1}^{N} W_{m,n} \\cdot X_{i-m, j-n} + b\n",
    "     $$\n",
    "     where:\n",
    "     - \\( X' \\): Output feature map after convolution.\n",
    "     - \\( W_{m,n} \\): Convolution kernel of size \\( M \\times N \\).\n",
    "     - \\( b \\): Bias term.\n",
    "     - \\( i, j \\): Spatial indices.\n",
    "\n",
    "   - After convolution, batch normalization and ReLU activation are applied:\n",
    "     $$\n",
    "     X'' = \\text{ReLU}(\\text{BatchNorm}(X'))\n",
    "     $$\n",
    "\n",
    "3. **Residual Blocks**: ResNet introduces residual connections to facilitate learning in deep networks. \n",
    "   - Each **Residual Block** contains two convolutions with weights \\( W_1 \\) and \\( W_2 \\) and applies a skip connection:\n",
    "     $$\n",
    "     Y = X + F(X) = X + \\text{ReLU}(\\text{BatchNorm}(W_2 * \\text{ReLU}(\\text{BatchNorm}(W_1 * X))))\n",
    "     $$\n",
    "     where:\n",
    "     - \\( Y \\): Block output after residual connection.\n",
    "     - \\( F(X) \\): Transformation applied to \\( X \\) via convolutions, batch normalization, and activation.\n",
    "\n",
    "4. **Downsampling**: Strided convolutions are used to reduce spatial dimensions while increasing the number of channels:\n",
    "   $$\n",
    "   X_{\\text{downsampled}} = W_{\\text{stride=2}} * X\n",
    "   $$\n",
    "\n",
    "The encoder output consists of multi-level feature maps, capturing complex image patterns necessary for effective denoising.\n",
    "\n",
    "#### Skip Connections\n",
    "\n",
    "Skip connections between corresponding encoder and decoder layers retain spatial information:\n",
    "   $$\n",
    "   F_{\\text{skip}} = \\text{Concat}(F_{\\text{encoder}}, F_{\\text{decoder}})\n",
    "   $$\n",
    "   where:\n",
    "   - \\( F_{\\text{encoder}} \\): Feature map from the encoder.\n",
    "   - \\( F_{\\text{decoder}} \\): Feature map in the decoder at the same level.\n",
    "\n",
    "#### SCSE Attention Block\n",
    "\n",
    "The **SCSE (Spatial and Channel Squeeze & Excitation)** Block selectively emphasizes important channels and spatial regions.\n",
    "\n",
    "1. **Channel Attention (CSE)**:\n",
    "   - **Global Average Pooling**: For each channel \\( c \\), compute a scalar summary:\n",
    "     $$\n",
    "     z_c = \\frac{1}{H \\times W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} F_{c, i, j}\n",
    "     $$\n",
    "     where:\n",
    "     - \\( z_c \\): Aggregated channel information.\n",
    "     - \\( F_{c, i, j} \\): Feature map value at channel \\( c \\) and location \\( (i, j) \\).\n",
    "\n",
    "   - **Fully Connected Layers**: Transform this summary into attention weights using two fully connected layers:\n",
    "     $$\n",
    "     s_c = \\sigma(W_2 \\cdot \\text{ReLU}(W_1 \\cdot z_c))\n",
    "     $$\n",
    "     where:\n",
    "     - \\( s_c \\): Attention weight for channel \\( c \\).\n",
    "     - \\( \\sigma \\): Sigmoid activation function.\n",
    "\n",
    "   - **Channel Scaling**: Scale each channel \\( F_c \\) by \\( s_c \\):\n",
    "     $$\n",
    "     F_c' = s_c \\cdot F_c\n",
    "     $$\n",
    "\n",
    "2. **Spatial Attention (SSE)**:\n",
    "   - **Spatial Convolution**: A convolution generates a spatial attention map \\( M \\):\n",
    "     $$\n",
    "     M_{i,j} = \\sigma(\\text{Conv2D}(F))\n",
    "     $$\n",
    "     where \\( M_{i,j} \\) is the spatial weight at location \\( (i, j) \\).\n",
    "\n",
    "   - **Spatial Scaling**: Apply \\( M_{i,j} \\) to refine the spatial features in \\( F \\):\n",
    "     $$\n",
    "     F_{i,j}' = M_{i,j} \\cdot F_{i,j}\n",
    "     $$\n",
    "\n",
    "Combining channel and spatial attention in the SCSE block results in a refined feature map \\( F'' \\) that enhances important features while suppressing irrelevant details.\n",
    "\n",
    "#### Decoder (Image Reconstruction)\n",
    "\n",
    "The decoder reconstructs a denoised image from the encoder’s multi-scale features:\n",
    "\n",
    "1. **Upsampling**:\n",
    "   - Each decoder layer upsamples the feature maps by a factor of 2 using transpose convolutions:\n",
    "     $$\n",
    "     F_{\\text{upsampled}} = \\text{TransposeConv}(F)\n",
    "     $$\n",
    "\n",
    "2. **Skip Connection Concatenation**: Combine the upsampled feature maps with corresponding encoder feature maps:\n",
    "   $$\n",
    "   F_{\\text{decoded}} = \\text{Concat}(F_{\\text{upsampled}}, F_{\\text{skip}})\n",
    "   $$\n",
    "\n",
    "3. **Final Convolution**: The final 1x1 convolution produces the denoised image, aligning with the input dimensions:\n",
    "   $$\n",
    "   Y_{\\text{output}} = W_{\\text{final}} * F_{\\text{decoded}}\n",
    "   $$\n",
    "\n",
    "## 2. Handling Variable Image Sizes\n",
    "\n",
    "To handle images of different sizes without distortion, **adaptive padding** is used to match the largest image dimensions in each batch:\n",
    "   $$\n",
    "   X_{\\text{padded}} = \\text{ZeroPad}(X, (H_{\\max}, W_{\\max}))\n",
    "   $$\n",
    "\n",
    "## 3. Dataset Management\n",
    "\n",
    "### Dataset Components\n",
    "- **Degraded Images**: Noisy images requiring denoising.\n",
    "- **Defect Masks**: Binary masks indicating regions with important features.\n",
    "- **Ground Truth**: Clean images used as targets for training.\n",
    "\n",
    "### Data Splitting\n",
    "The dataset is split as follows:\n",
    "   - **Training Set (70%)**: Used to learn patterns in noisy data.\n",
    "   - **Validation Set (20%)**: Monitors performance during training.\n",
    "   - **Test Set (10%)**: Evaluates final model generalization.\n",
    "\n",
    "## 4. Training Setup\n",
    "\n",
    "### Loss Function: Weighted MSE Loss\n",
    "\n",
    "A weighted Mean Squared Error (MSE) loss gives more importance to defect regions, preserving critical details in the denoised image:\n",
    "\n",
    "1. **Weighted Loss Definition**:\n",
    "   $$\n",
    "   \\text{Loss} = \\text{MSE}_{\\text{non-masked}} + \\lambda \\cdot \\text{MSE}_{\\text{masked}}\n",
    "   $$\n",
    "   where \\( \\lambda \\) is a weighting factor for the defect (masked) areas.\n",
    "\n",
    "### Optimizer: AdamW\n",
    "   - **AdamW** optimizer with weight decay provides regularization, handling noisy gradients effectively:\n",
    "     $$\n",
    "     \\theta_{t+1} = \\theta_t - \\alpha \\frac{m_t}{\\sqrt{v_t} + \\epsilon} - \\text{weight decay} \\cdot \\theta_t\n",
    "     $$\n",
    "     where:\n",
    "     - \\( \\theta_t \\): Parameter at step \\( t \\).\n",
    "     - \\( m_t, v_t \\): Exponentially decayed averages of gradients.\n",
    "     - \\( \\alpha \\): Learning rate.\n",
    "     - \\( \\epsilon \\): Small constant to avoid division by zero.\n",
    "\n",
    "### Learning Rate Adjustment\n",
    "   - **Scheduler (`ReduceLROnPlateau`)**: Adjusts learning rate when validation loss plateaus, enhancing convergence stability.\n",
    "\n",
    "## 5. Evaluation Metrics\n",
    "\n",
    "### Peak Signal-to-Noise Ratio (PSNR)\n",
    "   - **PSNR** measures the pixel-level similarity of the denoised output to the ground truth:\n",
    "     $$\n",
    "     \\text{PSNR} = 10 \\cdot \\log_{10} \\left( \\frac{\\text{MAX}^2}{\\text{MSE}} \\right)\n",
    "     $$\n",
    "     where \\( \\text{MAX} \\) is the maximum possible pixel value (e.g., 255 for 8-bit images).\n",
    "\n",
    "### Structural Similarity Index (SSIM)\n",
    "   - SSIM evaluates perceptual quality, incorporating luminance, contrast, and structure:\n",
    "     $$\n",
    "     \\text{SSIM}(x, y) = \\frac{(2 \\mu_x \\mu_y + C_1)(2 \\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_x^2 + \\\\mu_y^2 + C_1)(\\\\sigma_x^2 + \\\\sigma_y^2 + C_2)}\n",
    "     $$\n",
    "     where:\n",
    "     - \\( x \\) and \\( y \\): The two images being compared (e.g., denoised output and ground truth).\n",
    "     - \\( \\mu_x \\) and \\( \\mu_y \\): Mean pixel intensities of \\( x \\) and \\( y \\), respectively.\n",
    "     - \\( \\sigma_x^2 \\) and \\( \\sigma_y^2 \\): Variances of \\( x \\) and \\( y \\), respectively.\n",
    "     - \\( \\sigma_{xy} \\): Covariance between \\( x \\) and \\( y \\).\n",
    "     - \\( C_1 \\) and \\( C_2 \\): Stabilization constants to avoid division by zero.\n",
    "\n",
    "SSIM values range from 0 to 1, with values closer to 1 indicating higher similarity, which is useful for assessing perceptual quality in denoising.\n",
    "\n",
    "## 6. Algorithmic Summary\n",
    "\n",
    "1. **Input Preparation**:\n",
    "   - Load degraded (noisy) images, ground truth images, and defect masks.\n",
    "\n",
    "2. **Encoder (ResNet)**:\n",
    "   - Pass the input through convolutional layers and residual blocks with downsampling.\n",
    "\n",
    "3. **SCSE Attention Mechanism**:\n",
    "   - Apply Channel Attention (CSE) to prioritize significant channels.\n",
    "   - Apply Spatial Attention (SSE) to highlight critical spatial regions.\n",
    "\n",
    "4. **Decoder**:\n",
    "   - Upsample the refined features.\n",
    "   - Combine with skip connections from the encoder to retain spatial details.\n",
    "\n",
    "5. **Output Layer**:\n",
    "   - Apply a final 1x1 convolution to produce the denoised RGB image.\n",
    "\n",
    "6. **Loss Calculation**:\n",
    "   - Compute the **Weighted MSE Loss** on masked (defect) and non-masked areas.\n",
    "\n",
    "7. **Optimization (AdamW)**:\n",
    "   - Update parameters using AdamW optimizer with weight decay.\n",
    "\n",
    "8. **Evaluation**:\n",
    "   - Calculate PSNR for pixel accuracy and SSIM for perceptual quality.\n",
    "\n",
    "## Summary\n",
    "\n",
    "This architecture and training setup is designed to address the unique challenges of image denoising, such as preserving critical features and removing unwanted noise, using a combination of ResNet encoding, SCSE attention, weighted loss, and effective evaluation metrics (PSNR and SSIM). Together, these components allow for high-quality denoised outputs suitable for various real-world applications.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
